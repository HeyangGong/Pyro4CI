{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用 JIP\n",
    "\n",
    "**Using the PyTorch JIT(Just-In-Time) Compiler with Pyro**\n",
    "\n",
    "在 PyTorch 1.0 中，其首次引进了 torch.jit，它是一组编译工具，且主要目标是弥补研究与产品部署的差距。JIT 包含一种名为 Torch Script 的语言，这种语言是 Python 的子语言。使用 Torch Script 的代码可以实现非常大的优化，并且可以序列化以供在后续的 C++API 中使用。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial shows how to use the PyTorch [jit compiler](https://pytorch.org/docs/master/jit.html) in Pyro models.\n",
    "\n",
    "> Summary:\n",
    "\n",
    "- You can use compiled functions in Pyro models.\n",
    "- You cannot use pyro primitives inside compiled functions.\n",
    "- If your model has static structure, you can use a `Jit*` version of an `ELBO` algorithm, e.g.\n",
    "  ```diff\n",
    "  - Trace_ELBO()\n",
    "  + JitTrace_ELBO()\n",
    "  ```\n",
    "- The [HMC](http://docs.pyro.ai/en/dev/mcmc.html#pyro.infer.mcmc.HMC) and [NUTS](http://docs.pyro.ai/en/dev/mcmc.html#pyro.infer.mcmc.NUTS) classes accept `jit_compile=True` kwarg.\n",
    "- Models should input all tensors as `*args` and all non-tensors as `**kwargs`.\n",
    "- Each different value of `**kwargs` triggers a separate compilation.\n",
    "- Use `**kwargs` to specify all variation in structure (e.g. time series length).\n",
    "- To ignore jit warnings in safe code blocks, use `with pyro.util.ignore_jit_warnings():`.\n",
    "- To ignore all jit warnings in `HMC` or `NUTS`, pass `ignore_jit_warnings=True`.\n",
    "\n",
    "Table of contents：\n",
    "\n",
    "- [Introduction](#Introduction)\n",
    "- [A simple model](#A-simple-model)\n",
    "- [Varying structure](#Varying-structure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "from torch.distributions import constraints\n",
    "from pyro import poutine\n",
    "from pyro.distributions.util import broadcast_shape\n",
    "from pyro.infer import Trace_ELBO, JitTrace_ELBO, TraceEnum_ELBO, JitTraceEnum_ELBO, SVI\n",
    "from pyro.infer.mcmc import MCMC, NUTS\n",
    "from pyro.infer.autoguide import AutoDiagonalNormal\n",
    "from pyro.optim import Adam\n",
    "\n",
    "smoke_test = ('CI' in os.environ)\n",
    "assert pyro.__version__.startswith('0.4.1')\n",
    "pyro.enable_validation(True)    # <---- This is always a good idea!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "PyTorch 使用 jit compiler 来加速模型，可以理解成 pytorch 的静态模式 like tensorflow。\n",
    "\n",
    "PyTorch 1.0 includes a [jit compiler](https://pytorch.org/docs/master/jit.html) to speed up models. You can think of compilation as a \"static mode\", whereas PyTorch usually operates in \"eager mode\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Pyro 如何使用 jit) Pyro supports the jit compiler in two ways. \n",
    "\n",
    "- First you can use compiled functions inside Pyro models (but those functions cannot contain Pyro primitives).\n",
    "- Second, you can use Pyro's jit inference algorithms to compile entire inference steps; in static models this can reduce the Python overhead of Pyro models and speed up inference.\n",
    "\n",
    "The rest of this tutorial focuses on Pyro's jitted inference algorithms: [JitTrace_ELBO](http://docs.pyro.ai/en/dev/inference_algos.html#pyro.infer.trace_elbo.JitTrace_ELBO), [JitTraceGraph_ELBO](http://docs.pyro.ai/en/dev/inference_algos.html#pyro.infer.tracegraph_elbo.JitTraceGraph_ELBO), [JitTraceEnum_ELBO](http://docs.pyro.ai/en/dev/inference_algos.html#pyro.infer.traceenum_elbo.JitTraceEnum_ELBO), [JitMeanField_ELBO](http://docs.pyro.ai/en/dev/inference_algos.html#pyro.infer.trace_mean_field_elbo.JitTraceMeanField_ELBO), [HMC(jit_compile=True)](http://docs.pyro.ai/en/dev/mcmc.html#pyro.infer.mcmc.HMC), and [NUTS(jit_compile=True)](http://docs.pyro.ai/en/dev/mcmc.html#pyro.infer.mcmc.NUTS). For further reading, see the [examples/](https://github.com/uber/pyro/tree/dev/examples) directory, where most examples include a `--jit` option to run in compiled mode."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 一个简单的模型\n",
    "\n",
    "A simple model, 一个用 jit 提高速度的例子。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVI 推断方法\n",
    "\n",
    "\n",
    "Let's start with a simple Gaussian model and an [autoguide](http://docs.pyro.ai/en/dev/infer.autoguide.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(data):\n",
    "    loc = pyro.sample(\"loc\", dist.Normal(0., 10.))\n",
    "    scale = pyro.sample(\"scale\", dist.LogNormal(0., 3.))\n",
    "    with pyro.plate(\"data\", data.size(0)):\n",
    "        pyro.sample(\"obs\", dist.Normal(loc, scale), obs=data)\n",
    "\n",
    "guide = AutoDiagonalNormal(model)\n",
    "\n",
    "data = dist.Normal(0.5, 2.).sample((100,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's run as usual with an SVI object and `Trace_ELBO`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.48 s, sys: 31 ms, total: 3.51 s\n",
      "Wall time: 3.54 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pyro.clear_param_store()\n",
    "elbo = Trace_ELBO()\n",
    "svi = SVI(model, guide, Adam({'lr': 0.01}), elbo)\n",
    "for i in range(2 if smoke_test else 1000):\n",
    "    svi.step(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next to run with a jit compiled inference, we simply replace\n",
    "```diff\n",
    "- elbo = Trace_ELBO()\n",
    "+ elbo = JitTrace_ELBO()\n",
    "```\n",
    "Also note that the `AutoDiagonalNormal` guide behaves a little differently on its first invocation (it runs the model to produce a prototype trace), and we don't want to record this warmup behavior when compiling. Thus we call the `guide(data)` once to initialize, then run the compiled SVI,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.59 s, sys: 28.7 ms, total: 1.62 s\n",
      "Wall time: 1.64 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pyro.clear_param_store()\n",
    "\n",
    "guide(data)  # Do any lazy initialization before compiling.\n",
    "\n",
    "elbo = JitTrace_ELBO()\n",
    "svi = SVI(model, guide, Adam({'lr': 0.01}), elbo)\n",
    "for i in range(2 if smoke_test else 1000):\n",
    "    svi.step(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NUTS 推断方法\n",
    "\n",
    "Notice that we have a more than 2x speedup for this small model.\n",
    "\n",
    "Let us now use the same model, but we will instead use MCMC to generate samples from the model's posterior. We will use the No-U-Turn(NUTS) sampler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 100%|████████████████████████████████████| 200/200 [00:02<00:00, 72.53it/s, step size=6.20e-01, acc. prob=0.961]                         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.72 s, sys: 42.4 ms, total: 2.76 s\n",
      "Wall time: 2.78 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "nuts_kernel = NUTS(model)\n",
    "pyro.set_rng_seed(1)\n",
    "mcmc_run = MCMC(nuts_kernel, num_samples=100).run(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can compile the potential energy computation in NUTS using the `jit_compile=True` argument to the NUTS kernel. We also silence JIT warnings due to the presence of tensor constants in the model by using `ignore_jit_warnings=True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 100%|███████████████████████████████████| 200/200 [00:01<00:00, 129.67it/s, step size=6.20e-01, acc. prob=0.961]                         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.51 s, sys: 34.2 ms, total: 1.55 s\n",
      "Wall time: 1.55 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "nuts_kernel = NUTS(model, jit_compile=True, ignore_jit_warnings=True)\n",
    "pyro.set_rng_seed(1)\n",
    "mcmc_run = MCMC(nuts_kernel, num_samples=100).run(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We notice a significant increase in sampling throughput when JIT compilation is enabled."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加速时间序列模型\n",
    "\n",
    "Varying structure\n",
    "\n",
    "Time series models often run on datasets of multiple time series with different lengths. To accomodate varying structure like this, Pyro requires models to separate all model inputs into tensors and non-tensors.$^\\dagger$\n",
    "\n",
    "- Non-tensor inputs should be passed as `**kwargs` to the model and guide. These can determine model structure, so that a model is compiled for each value of the passed `**kwargs`.\n",
    "- Tensor inputs should be passed as `*args`. These must not determine model structure. However `len(args)` may determine model structure (as is used e.g. in semisupervised models).\n",
    "\n",
    "To illustrate this with a time series model, we will pass in a sequence of observations as a tensor `arg` and the sequence length as a non-tensor `kwarg`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"325pt\" height=\"188pt\"\n",
       " viewBox=\"0.00 0.00 324.99 188.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 184)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-184 320.9931,-184 320.9931,4 -4,4\"/>\n",
       "<!-- x_t -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>x_t</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"246.3956\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"246.3956\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">x_t</text>\n",
       "</g>\n",
       "<!-- y_t -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>y_t</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"159.3956\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"159.3956\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">y_t</text>\n",
       "</g>\n",
       "<!-- x_t&#45;&gt;y_t -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>x_t&#45;&gt;y_t</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M229.2072,-75.7751C216.4573,-65.2234 198.8767,-50.674 184.548,-38.8157\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"186.4838,-35.8747 176.5483,-32.1953 182.0208,-41.2674 186.4838,-35.8747\"/>\n",
       "</g>\n",
       "<!-- emit_scale -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>emit_scale</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"49.3956\" cy=\"-90\" rx=\"49.2915\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"49.3956\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">emit_scale</text>\n",
       "</g>\n",
       "<!-- emit_scale&#45;&gt;y_t -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>emit_scale&#45;&gt;y_t</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M73.5356,-74.1993C90.5538,-63.0601 113.4003,-48.106 131.2478,-36.424\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"133.6176,-39.056 140.0678,-30.6509 129.784,-33.1991 133.6176,-39.056\"/>\n",
       "</g>\n",
       "<!-- emit_loc -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>emit_loc</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"159.3956\" cy=\"-90\" rx=\"42.4939\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"159.3956\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">emit_loc</text>\n",
       "</g>\n",
       "<!-- emit_loc&#45;&gt;y_t -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>emit_loc&#45;&gt;y_t</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M159.3956,-71.8314C159.3956,-64.131 159.3956,-54.9743 159.3956,-46.4166\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"162.8957,-46.4132 159.3956,-36.4133 155.8957,-46.4133 162.8957,-46.4132\"/>\n",
       "</g>\n",
       "<!-- x_{t&#45;1} -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>x_{t&#45;1}</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"203.3956\" cy=\"-162\" rx=\"38.1938\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"203.3956\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">x_{t&#45;1}</text>\n",
       "</g>\n",
       "<!-- x_{t&#45;1}&#45;&gt;x_t -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>x_{t&#45;1}&#45;&gt;x_t</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M213.8047,-144.5708C219.0034,-135.8661 225.3934,-125.1665 231.1338,-115.5546\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"234.2559,-117.153 236.3785,-106.7729 228.2461,-113.5637 234.2559,-117.153\"/>\n",
       "</g>\n",
       "<!-- trans -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>trans</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"288.3956\" cy=\"-162\" rx=\"28.6953\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"288.3956\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">trans</text>\n",
       "</g>\n",
       "<!-- trans&#45;&gt;x_t -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>trans&#45;&gt;x_t</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M278.4422,-144.937C273.3685,-136.2393 267.0922,-125.4799 261.4426,-115.7948\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"264.3396,-113.8148 256.2776,-106.9405 258.2931,-117.3419 264.3396,-113.8148\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x12995eba8>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from graphviz import Source\n",
    "Source('Digraph{x_t, emit_scale, emit_loc -> y_t; \"x_{t-1}\", trans -> x_t; }')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(sequence, num_sequences, length, state_dim=16):\n",
    "    # This is a Gaussian HMM model.\n",
    "    with pyro.plate(\"states\", state_dim):\n",
    "        trans = pyro.sample(\"trans\", dist.Dirichlet(0.5 * torch.ones(state_dim)))\n",
    "        emit_loc = pyro.sample(\"emit_loc\", dist.Normal(0., 10.))\n",
    "    emit_scale = pyro.sample(\"emit_scale\", dist.LogNormal(0., 3.))\n",
    "\n",
    "    # We're doing manual data subsampling, so we need to scale to actual data size.\n",
    "    with poutine.scale(scale=num_sequences):\n",
    "        # We'll use enumeration inference over the hidden x.\n",
    "        x = 0\n",
    "        for t in pyro.markov(range(length)):\n",
    "            x = pyro.sample(\"x_{}\".format(t), dist.Categorical(trans[x]),\n",
    "                            infer={\"enumerate\": \"parallel\"})\n",
    "            pyro.sample(\"y_{}\".format(t), dist.Normal(emit_loc[x], emit_scale),\n",
    "                        obs=sequence[t])\n",
    "\n",
    "guide = AutoDiagonalNormal(poutine.block(model, expose=[\"trans\", \"emit_scale\", \"emit_loc\"]))\n",
    "\n",
    "# This is fake data of different lengths.\n",
    "lengths = [24] * 50 + [48] * 20 + [72] * 5\n",
    "sequences = [torch.randn(length) for length in lengths]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets' run SVI as usual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 58 s, sys: 303 ms, total: 58.3 s\n",
      "Wall time: 58.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pyro.clear_param_store()\n",
    "elbo = TraceEnum_ELBO(max_plate_nesting=1)\n",
    "svi = SVI(model, guide, Adam({'lr': 0.01}), elbo)\n",
    "for i in range(1 if smoke_test else 10):\n",
    "    for sequence in sequences:\n",
    "        svi.step(sequence,                                            # tensor args\n",
    "                 num_sequences=len(sequences), length=len(sequence))  # non-tensor args"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again we'll simply swap in a `Jit*` implementation\n",
    "```diff\n",
    "- elbo = TraceEnum_ELBO(max_plate_nesting=1)\n",
    "+ elbo = JitTraceEnum_ELBO(max_plate_nesting=1)\n",
    "```\n",
    "Note that we are manually specifying the `max_plate_nesting` arg. Usually Pyro can figure this out automatically by running the model once on the first invocation; however to avoid this extra work when we run the compiler on the first step, we pass this in manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 41 s, sys: 242 ms, total: 41.3 s\n",
      "Wall time: 41.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pyro.clear_param_store()\n",
    "\n",
    "# Do any lazy initialization before compiling.\n",
    "guide(sequences[0], num_sequences=len(sequences), length=len(sequences[0]))\n",
    "\n",
    "elbo = JitTraceEnum_ELBO(max_plate_nesting=1)\n",
    "svi = SVI(model, guide, Adam({'lr': 0.01}), elbo)\n",
    "for i in range(1 if smoke_test else 10):\n",
    "    for sequence in sequences:\n",
    "        svi.step(sequence,                                            # tensor args\n",
    "                 num_sequences=len(sequences), length=len(sequence))  # non-tensor args"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again we see more than 2x speedup. Note that since there were three different sequence lengths, compilation was triggered three times.\n",
    "\n",
    "$^\\dagger$ Note this section is only valid for SVI, and HMC/NUTS assume fixed model arguments."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
